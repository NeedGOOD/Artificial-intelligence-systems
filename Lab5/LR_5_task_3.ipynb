{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPf0ZazIvXCNKFYwL9Sp8bL"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"N3bKO5S8wAMK","executionInfo":{"status":"ok","timestamp":1733955942284,"user_tz":-120,"elapsed":28134,"user":{"displayName":"Владислав Якусевич","userId":"11646516463393647380"}},"outputId":"2c915a98-1563-473b-997e-40f34468ec68"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","### Searching optimal parameters for precision_weighted\n","\n","Grid scores for the parameter grid:\n","\n","{'max_depth': 2, 'n_estimators': 25} --> 0.838\n","\n","Best parameters for precision_weighted :\n"," {'max_depth': 2, 'n_estimators': 100}\n","{'max_depth': 2, 'n_estimators': 50} --> 0.845\n","\n","Best parameters for precision_weighted :\n"," {'max_depth': 2, 'n_estimators': 100}\n","{'max_depth': 2, 'n_estimators': 100} --> 0.85\n","\n","Best parameters for precision_weighted :\n"," {'max_depth': 2, 'n_estimators': 100}\n","{'max_depth': 2, 'n_estimators': 250} --> 0.846\n","\n","Best parameters for precision_weighted :\n"," {'max_depth': 2, 'n_estimators': 100}\n","{'max_depth': 4, 'n_estimators': 25} --> 0.846\n","\n","Best parameters for precision_weighted :\n"," {'max_depth': 2, 'n_estimators': 100}\n","{'max_depth': 4, 'n_estimators': 50} --> 0.84\n","\n","Best parameters for precision_weighted :\n"," {'max_depth': 2, 'n_estimators': 100}\n","{'max_depth': 4, 'n_estimators': 100} --> 0.841\n","\n","Best parameters for precision_weighted :\n"," {'max_depth': 2, 'n_estimators': 100}\n","{'max_depth': 4, 'n_estimators': 250} --> 0.845\n","\n","Best parameters for precision_weighted :\n"," {'max_depth': 2, 'n_estimators': 100}\n","{'max_depth': 8, 'n_estimators': 25} --> 0.846\n","\n","Best parameters for precision_weighted :\n"," {'max_depth': 2, 'n_estimators': 100}\n","{'max_depth': 8, 'n_estimators': 50} --> 0.845\n","\n","Best parameters for precision_weighted :\n"," {'max_depth': 2, 'n_estimators': 100}\n","{'max_depth': 8, 'n_estimators': 100} --> 0.842\n","\n","Best parameters for precision_weighted :\n"," {'max_depth': 2, 'n_estimators': 100}\n","{'max_depth': 8, 'n_estimators': 250} --> 0.836\n","\n","Best parameters for precision_weighted :\n"," {'max_depth': 2, 'n_estimators': 100}\n","{'max_depth': 12, 'n_estimators': 25} --> 0.83\n","\n","Best parameters for precision_weighted :\n"," {'max_depth': 2, 'n_estimators': 100}\n","{'max_depth': 12, 'n_estimators': 50} --> 0.827\n","\n","Best parameters for precision_weighted :\n"," {'max_depth': 2, 'n_estimators': 100}\n","{'max_depth': 12, 'n_estimators': 100} --> 0.832\n","\n","Best parameters for precision_weighted :\n"," {'max_depth': 2, 'n_estimators': 100}\n","{'max_depth': 12, 'n_estimators': 250} --> 0.828\n","\n","Best parameters for precision_weighted :\n"," {'max_depth': 2, 'n_estimators': 100}\n","{'max_depth': 16, 'n_estimators': 25} --> 0.811\n","\n","Best parameters for precision_weighted :\n"," {'max_depth': 2, 'n_estimators': 100}\n","{'max_depth': 16, 'n_estimators': 50} --> 0.818\n","\n","Best parameters for precision_weighted :\n"," {'max_depth': 2, 'n_estimators': 100}\n","{'max_depth': 16, 'n_estimators': 100} --> 0.816\n","\n","Best parameters for precision_weighted :\n"," {'max_depth': 2, 'n_estimators': 100}\n","{'max_depth': 16, 'n_estimators': 250} --> 0.817\n","\n","Best parameters for precision_weighted :\n"," {'max_depth': 2, 'n_estimators': 100}\n","\n","### Searching optimal parameters for recall_weighted\n","\n","Grid scores for the parameter grid:\n","\n","{'max_depth': 2, 'n_estimators': 25} --> 0.833\n","\n","Best parameters for recall_weighted :\n"," {'max_depth': 2, 'n_estimators': 100}\n","{'max_depth': 2, 'n_estimators': 50} --> 0.837\n","\n","Best parameters for recall_weighted :\n"," {'max_depth': 2, 'n_estimators': 100}\n","{'max_depth': 2, 'n_estimators': 100} --> 0.843\n","\n","Best parameters for recall_weighted :\n"," {'max_depth': 2, 'n_estimators': 100}\n","{'max_depth': 2, 'n_estimators': 250} --> 0.841\n","\n","Best parameters for recall_weighted :\n"," {'max_depth': 2, 'n_estimators': 100}\n","{'max_depth': 4, 'n_estimators': 25} --> 0.843\n","\n","Best parameters for recall_weighted :\n"," {'max_depth': 2, 'n_estimators': 100}\n","{'max_depth': 4, 'n_estimators': 50} --> 0.836\n","\n","Best parameters for recall_weighted :\n"," {'max_depth': 2, 'n_estimators': 100}\n","{'max_depth': 4, 'n_estimators': 100} --> 0.837\n","\n","Best parameters for recall_weighted :\n"," {'max_depth': 2, 'n_estimators': 100}\n","{'max_depth': 4, 'n_estimators': 250} --> 0.841\n","\n","Best parameters for recall_weighted :\n"," {'max_depth': 2, 'n_estimators': 100}\n","{'max_depth': 8, 'n_estimators': 25} --> 0.841\n","\n","Best parameters for recall_weighted :\n"," {'max_depth': 2, 'n_estimators': 100}\n","{'max_depth': 8, 'n_estimators': 50} --> 0.84\n","\n","Best parameters for recall_weighted :\n"," {'max_depth': 2, 'n_estimators': 100}\n","{'max_depth': 8, 'n_estimators': 100} --> 0.839\n","\n","Best parameters for recall_weighted :\n"," {'max_depth': 2, 'n_estimators': 100}\n","{'max_depth': 8, 'n_estimators': 250} --> 0.834\n","\n","Best parameters for recall_weighted :\n"," {'max_depth': 2, 'n_estimators': 100}\n","{'max_depth': 12, 'n_estimators': 25} --> 0.828\n","\n","Best parameters for recall_weighted :\n"," {'max_depth': 2, 'n_estimators': 100}\n","{'max_depth': 12, 'n_estimators': 50} --> 0.825\n","\n","Best parameters for recall_weighted :\n"," {'max_depth': 2, 'n_estimators': 100}\n","{'max_depth': 12, 'n_estimators': 100} --> 0.83\n","\n","Best parameters for recall_weighted :\n"," {'max_depth': 2, 'n_estimators': 100}\n","{'max_depth': 12, 'n_estimators': 250} --> 0.827\n","\n","Best parameters for recall_weighted :\n"," {'max_depth': 2, 'n_estimators': 100}\n","{'max_depth': 16, 'n_estimators': 25} --> 0.809\n","\n","Best parameters for recall_weighted :\n"," {'max_depth': 2, 'n_estimators': 100}\n","{'max_depth': 16, 'n_estimators': 50} --> 0.816\n","\n","Best parameters for recall_weighted :\n"," {'max_depth': 2, 'n_estimators': 100}\n","{'max_depth': 16, 'n_estimators': 100} --> 0.815\n","\n","Best parameters for recall_weighted :\n"," {'max_depth': 2, 'n_estimators': 100}\n","{'max_depth': 16, 'n_estimators': 250} --> 0.815\n","\n","Best parameters for recall_weighted :\n"," {'max_depth': 2, 'n_estimators': 100}\n","\n","Performance report on test set:\n","\n","              precision    recall  f1-score   support\n","\n","         0.0       0.94      0.81      0.87        79\n","         1.0       0.81      0.86      0.83        70\n","         2.0       0.83      0.91      0.87        76\n","\n","    accuracy                           0.86       225\n","   macro avg       0.86      0.86      0.86       225\n","weighted avg       0.86      0.86      0.86       225\n","\n"]}],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import classification_report\n","from sklearn.model_selection import train_test_split, GridSearchCV\n","from sklearn.ensemble import ExtraTreesClassifier\n","\n","# Завантаження даних\n","input_file = 'data_random_forests.txt' # Шлях до файлу\n","data = np.loadtxt(input_file, delimiter=',')\n","X, y = data[:, :-1], data[:, -1]\n","\n","# Розділення даних на навчальні та тестові набори\n","X_train, X_test, y_train, y_test = train_test_split(\n","  X, y, test_size=0.25, random_state=5\n",")\n","\n","# Визначення сітки значень параметрів\n","parameter_grid = {\n","  'n_estimators': [25, 50, 100, 250],\n","  'max_depth': [2, 4, 8, 12, 16]\n","}\n","metrics = ['precision_weighted', 'recall_weighted']\n","\n","# Перебір параметрів\n","for metric in metrics:\n","  print(\"\\n### Searching optimal parameters for\", metric)\n","\n","  classifier = GridSearchCV(\n","    ExtraTreesClassifier(random_state=0),\n","    parameter_grid,\n","    cv=5, # Кількість фолдів для крос-валідації\n","    scoring=metric\n","  )\n","\n","  # Навчання моделі\n","  classifier.fit(X_train, y_train)\n","\n","  # Виведення результатів\n","  print(\"\\nGrid scores for the parameter grid:\\n\")\n","  results = classifier.cv_results_\n","\n","  for mean, params in zip(results['mean_test_score'], results['params']):\n","    print(params, '-->', round(mean, 3))\n","    print(\"\\nBest parameters for\", metric, \":\\n\", classifier.best_params_)\n","\n","# Виведення результатів роботи класифікатора\n","print(\"\\nPerformance report on test set:\\n\")\n","y_pred = classifier.predict(X_test)\n","print(classification_report(y_test, y_pred))\n"]}]}